{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T09:40:29.821426Z",
     "start_time": "2024-10-20T09:40:18.363510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ImageDataGenerator\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1: Data Preprocessing\n",
    "data_dir = 'data/'\n",
    "img_width, img_height = 128, 128\n",
    "batch_size = 32\n",
    "epochs = 20"
   ],
   "id": "d6584c63a18fabf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_data_generators(data_dir, img_width, img_height, batch_size, train_ratio):\n",
    "    # Mengatur `validation_split` berdasarkan rasio train: test\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=1 - train_ratio  # Mengatur rasio validasi\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator"
   ],
   "id": "895c24dfe92b15da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 2: Model Building\n",
    "model = Sequential([\n",
    "    # Layer Konvolusi 1\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Layer Konvolusi 2\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Layer Konvolusi 3\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Layer Flatten\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully Connected Layer 1\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),  # Preventing Overfitting\n",
    "\n",
    "    # Fully Connected Layer 2 (Output)\n",
    "    Dense(3, activation='softmax')  # 3 kelas: dog, cat, snake\n",
    "])\n",
    "\n",
    "# Step 3: Kompilasi Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "id": "1fddad4497fd3f39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Skenario 1: 30% Train, 70% Test\n",
    "train_generator_30, validation_generator_70 = create_data_generators(data_dir, img_width, img_height, batch_size, train_ratio=0.3)\n",
    "print(\"Training dengan rasio 30% Train dan 70% Test\")\n",
    "model.fit(\n",
    "    train_generator_30,\n",
    "    steps_per_epoch=train_generator_30.samples // batch_size,\n",
    "    validation_data=validation_generator_70,\n",
    "    validation_steps=validation_generator_70.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Skenario 2: 50% Train, 50% Test\n",
    "train_generator_50, validation_generator_50 = create_data_generators(data_dir, img_width, img_height, batch_size, train_ratio=0.5)\n",
    "print(\"Training dengan rasio 50% Train dan 50% Test\")\n",
    "model.fit(\n",
    "    train_generator_50,\n",
    "    steps_per_epoch=train_generator_50.samples // batch_size,\n",
    "    validation_data=validation_generator_50,\n",
    "    validation_steps=validation_generator_50.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Skenario 3: 70% Train, 30% Test\n",
    "train_generator_70, validation_generator_30 = create_data_generators(data_dir, img_width, img_height, batch_size, train_ratio=0.7)\n",
    "print(\"Training dengan rasio 70% Train dan 30% Test\")\n",
    "model.fit(\n",
    "    train_generator_70,\n",
    "    steps_per_epoch=train_generator_70.samples // batch_size,\n",
    "    validation_data=validation_generator_30,\n",
    "    validation_steps=validation_generator_30.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ],
   "id": "e76f14aa6ed6c5da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
